% Encoding: UTF-8

@WWW{Senchanka2019,
  author  = {Senchanka, Pavel},
  date    = {2019-12-12},
  title   = {Example on-device model personalization with TensorFlow Lite},
  url     = {https://blog.tensorflow.org/2019/12/example-on-device-model-personalization.html},
  urldate = {2021-05-12},
}

@WWW{Sarkar2019,
  author  = {Dipanjan Sarkar},
  date    = {2019-11-14},
  title   = {A Comprehensive Hands-on Guide to Transfer Learning with Real-World Applications in Deep Learning},
  url     = {https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a},
  urldate = {2021-05-12},
}

@Article{Pellegrini2019,
  author      = {Lorenzo Pellegrini and Gabriele Graffieti and Vincenzo Lomonaco and Davide Maltoni},
  date        = {2019-12-02},
  title       = {Latent Replay for Real-Time Continual Learning},
  eprint      = {1912.01100},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  abstract    = {Training deep neural networks at the edge on light computational devices, embedded systems and robotic platforms is nowadays very challenging. Continual learning techniques, where complex models are incrementally trained on small batches of new data, can make the learning problem tractable even for CPU-only embedded devices enabling remarkable levels of adaptiveness and autonomy. However, a number of practical problems need to be solved: catastrophic forgetting before anything else. In this paper we introduce an original technique named "Latent Replay" where, instead of storing a portion of past data in the input space, we store activations volumes at some intermediate layer. This can significantly reduce the computation and storage required by native rehearsal. To keep the representation stable and the stored activations valid we propose to slow-down learning at all the layers below the latent replay one, leaving the layers above free to learn at full pace. In our experiments we show that Latent Replay, combined with existing continual learning techniques, achieves state-of-the-art performance on complex video benchmarks such as CORe50 NICv2 (with nearly 400 small and highly non-i.i.d. batches) and OpenLORIS. Finally, we demonstrate the feasibility of nearly real-time continual learning on the edge through the deployment of the proposed technique on a smartphone device.},
  keywords    = {cs.LG, cs.CV, stat.ML},
}

@Article{forgetting,
  author      = {James Kirkpatrick and Razvan Pascanu and Neil Rabinowitz and Joel Veness and Guillaume Desjardins and Andrei A. Rusu and Kieran Milan and John Quan and Tiago Ramalho and Agnieszka Grabska-Barwinska and Demis Hassabis and Claudia Clopath and Dharshan Kumaran and Raia Hadsell},
  title       = {Overcoming catastrophic forgetting in neural networks},
  date        = {2016-12-02},
  eprint      = {1612.00796v2},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  abstract    = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially.},
  file        = {online:http\://arxiv.org/pdf/1612.00796v2:PDF},
  keywords    = {cs.LG, cs.AI, stat.ML},
}

@Article{cl-vs-tl,
  author      = {Giorgos Demosthenous and Vassilis Vassiliades},
  title       = {Continual Learning on the Edge with TensorFlow Lite},
  date        = {2021-05-05},
  eprint      = {2105.01946v1},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  abstract    = {Deploying sophisticated deep learning models on embedded devices with the purpose of solving real-world problems is a struggle using today's technology. Privacy and data limitations, network connection issues, and the need for fast model adaptation are some of the challenges that constitute today's approaches unfit for many applications on the edge and make real-time on-device training a necessity. Google is currently working on tackling these challenges by embedding an experimental transfer learning API to their TensorFlow Lite, machine learning library. In this paper, we show that although transfer learning is a good first step for on-device model training, it suffers from catastrophic forgetting when faced with more realistic scenarios. We present this issue by testing a simple transfer learning model on the CORe50 benchmark as well as by demonstrating its limitations directly on an Android application we developed. In addition, we expand the TensorFlow Lite library to include continual learning capabilities, by integrating a simple replay approach into the head of the current transfer learning model. We test our continual learning model on the CORe50 benchmark to show that it tackles catastrophic forgetting, and we demonstrate its ability to continually learn, even under non-ideal conditions, using the application we developed. Finally, we open-source the code of our Android application to enable developers to integrate continual learning to their own smartphone applications, as well as to facilitate further development of continual learning functionality into the TensorFlow Lite environment.},
  file        = {online:http\://arxiv.org/pdf/2105.01946v1:PDF},
  keywords    = {cs.LG, cs.CV},
}

@Article{deepl-lecun,
  author = {Yann LeCun and Yoshua Bengio and Geoffrey Hinton},
  title  = {Deep learning},
  date   = {2015-05},
  file   = {:LeCun2015 - Deep learning.pdf:PDF},
}

@Article{deepl-vs-traditional,
  author       = {Niall O' Mahony and Sean Campbell and Anderson Carvalho and Suman Harapanahalli and Gustavo Velasco-Hernandez and Lenka Krpalkova and Daniel Riordan and Joseph Walsh},
  title        = {Deep Learning vs. Traditional Computer Vision},
  journaltitle = {in Advances in Computer Vision Proceedings of the 2019 Computer Vision Conference (CVC). Springer Nature Switzerland AG, pp. 128-144},
  date         = {2019-10-30},
  doi          = {10.1007/978-3-030-17795-9},
  eprint       = {1910.13796v1},
  eprintclass  = {cs.CV},
  eprinttype   = {arXiv},
  abstract     = {Deep Learning has pushed the limits of what was possible in the domain of Digital Image Processing. However, that is not to say that the traditional computer vision techniques which had been undergoing progressive development in years prior to the rise of DL have become obsolete. This paper will analyse the benefits and drawbacks of each approach. The aim of this paper is to promote a discussion on whether knowledge of classical computer vision techniques should be maintained. The paper will also explore how the two sides of computer vision can be combined. Several recent hybrid methodologies are reviewed which have demonstrated the ability to improve computer vision performance and to tackle problems not suited to Deep Learning. For example, combining traditional computer vision techniques with Deep Learning has been popular in emerging domains such as Panoramic Vision and 3D vision for which Deep Learning models have not yet been fully optimised},
  file         = {online:http\://arxiv.org/pdf/1910.13796v1:PDF},
  keywords     = {cs.CV, cs.LG},
}

@Article{mobilenet,
  author      = {Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
  title       = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  date        = {2017-04-17},
  eprint      = {1704.04861v1},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  abstract    = {We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.},
  file        = {online:http\://arxiv.org/pdf/1704.04861v1:PDF},
  keywords    = {cs.CV},
}

@Online{tflite-site,
  author  = {Tensorflow Lite Contributors},
  title   = {Deploy machine learning models on mobile and IoT devices},
  year    = {2021},
  url     = {https://www.tensorflow.org/lite},
  urldate = {2021-07-31},
}

@Online{sqlite-documentation,
  author  = {SQLite Contributors},
  title   = {What is SQLite?},
  date    = {2021-06-18},
  url     = {https://www.sqlite.org/index.html},
  urldate = {2021-08-03},
}

@Online{android:jetpack,
  author  = {Android Contributors},
  title   = {Android Jetpack},
  year    = {2021},
  url     = {https://developer.android.com/jetpack?hl=de},
  urldate = {2021-08-03},
}

@Online{android:camerax,
  author  = {Android Contributors},
  title   = {CameraX Overview},
  date    = {2021-03-19},
  url     = {https://developer.android.com/training/camerax?hl=de},
  urldate = {2021-08-04},
}

@Article{dl-review,
  author      = {Zhong-Qiu Zhao and Peng Zheng and Shou-tao Xu and Xindong Wu},
  title       = {Object Detection with Deep Learning: A Review},
  date        = {2018-07-15},
  eprint      = {1807.05511v2},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  abstract    = {Due to object detection's close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles which combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy and optimization function, etc. In this paper, we provide a review on deep learning based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely Convolutional Neural Network (CNN). Then we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network based learning systems.},
  file        = {online:http\://arxiv.org/pdf/1807.05511v2:PDF},
  keywords    = {cs.CV},
}

@Comment{jabref-meta: databaseType:biblatex;}
